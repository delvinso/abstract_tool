{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Modeling - LDA \n",
    "\n",
    "1. Implements cleaning and pre-processing from `data_exploration.ipynb` with additional text cleaning.\n",
    "2. Trains an LDA for each of the datasets, for each outcome (ie. abstracts fitting exclusion criteria and inclusion criteria separately), and prints the top words belonging to each topic.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re \n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize, regexp, RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/delvin/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/delvin/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import ssl\n",
    "\n",
    "try:\n",
    "    _create_unverified_https_context = ssl._create_unverified_context\n",
    "except AttributeError:\n",
    "    pass\n",
    "else:\n",
    "    ssl._create_default_https_context = _create_unverified_https_context\n",
    "\n",
    "# need to only download only once\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 01. Reading in and Cleaning \n",
    "**(mostly from data_exploration.ipynb)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# read in each dataset into a dictionary\n",
    "reviews = {}\n",
    "\n",
    "# assuming naming follows 'type' + '_complete.csv' structure \n",
    "for f in os.listdir('../data/'):\n",
    "    if not f.startswith('.'):\n",
    "        key = re.split(r'_', f)\n",
    "        reviews[key[0]] = f\n",
    "        \n",
    "PATH = os.path.abspath('../data')\n",
    "\n",
    "for key, dataset in reviews.items():\n",
    "    reviews[key] = pd.read_csv(os.path.join(PATH, dataset), encoding='latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# columns to keep\n",
    "to_keep = ['Title', 'Abstract', 'Notes', 'Inclusion']\n",
    "\n",
    "for key, dataset in reviews.items():\n",
    "    reviews[key] = dataset[to_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# join title and abstract together\n",
    "for key, dataset in reviews.items():\n",
    "    dataset['All_Text'] = dataset.apply(lambda x: f\"{x['Title']} {x['Abstract']}\",\n",
    "                                        axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# modified to remove 1 letter words and numbers. shouldn't be relevant\n",
    "def clean_text(s):\n",
    "    s = s.str.lower()                         # put to lowercase for homogeneity    \n",
    "    s = s.str.replace(r'_', ' ')              # remove underscores from the notes\n",
    "    s = s.str.replace(r'\\W', ' ')             # remove punctutation\n",
    "    stop = set(stopwords.words('english'))    # define stop words\n",
    "    lemmatizer = WordNetLemmatizer()          # lemmatize - a lot of repeat words\n",
    "\n",
    "    s = s.apply(lambda x: [lemmatizer.lemmatize(word, 'v')\n",
    "                              for word in x.split() \n",
    "                              if word not in stop]) # remove stopwords\n",
    "\n",
    "    s = s.apply(lambda x: [word for word in x if len(word) > 1])\n",
    "    s = s.apply(lambda x: [word for word in x if not word.isnumeric()])\n",
    "\n",
    "    return(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for key, dataset in reviews.items():\n",
    "    dataset[['All_Text']] = dataset[['All_Text']].apply(lambda x: clean_text(x))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 02. LDA\n",
    "\n",
    "TODO\n",
    "* how applicable is this given the nuances in exclusion/inclusion? - literature?\n",
    "* play around with dictionary filtering parameters\n",
    "* given a new 'All_Text' (abstract + title), return similar papers?\n",
    "* topic coherence\n",
    "* add n-gram\n",
    "* use small n to see how granular topics are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim import models, corpora\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def text2lda(txt, num_topics = 5):\n",
    "    \"\"\"\n",
    "    Creates a dictionary, filters based on document size and frequency. \n",
    "    Converts to a bag of words and fits a simple LDA.\n",
    "    \"\"\"\n",
    "    doc_size = txt.shape[0]\n",
    "    dictionary = corpora.Dictionary(txt)\n",
    "    # remove terms occuring in less 1% of documents, and those occuring in more than 30\n",
    "    dictionary.filter_extremes(no_below = doc_size * 0.01, no_above = 0.30)\n",
    "    corpus = [dictionary.doc2bow(text) for text in txt]\n",
    "    lda_model = models.LdaModel(corpus=corpus,\n",
    "                                num_topics = num_topics,\n",
    "                                id2word=dictionary,\n",
    "                                eval_every=None)\n",
    "    return(lda_model)\n",
    "\n",
    "def print_top_words(model,n = 10):\n",
    "    for topic in range(0, model.num_topics):\n",
    "        print('\\t\\tTopic {}: '.format(topic) + ', '.join(words[0] for words in model.show_topic(topic, n)))\n",
    "        # print('topic {}: '.format(topic) + ', '.join([str(words[1]) for words in model.show_topic(topic, 10)]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: Vitamin D, Inclusion: 0, # of Abstracts 1368\n",
      "\t\tTopic 0: bone, infants, pregnancy, patients, oh\n",
      "\t\tTopic 1: oh, bone, trials, infants, pregnancy\n",
      "\t\tTopic 2: children, placebo, iu, status, high\n",
      "\t\tTopic 3: trials, patients, bone, children, status\n",
      "\t\tTopic 4: pregnancy, infants, children, trials, data\n",
      "Dataset: Vitamin D, Inclusion: 1, # of Abstracts 80\n",
      "\t\tTopic 0: children, pneumonia, ml, nan, mo\n",
      "\t\tTopic 1: nmol, wk, breastfeed, mug, milk\n",
      "\t\tTopic 2: micronutrient, mo, breast, nmol, day\n",
      "\t\tTopic 3: ml, children, single, day, calcium\n",
      "\t\tTopic 4: ml, ng, breast, day, weeks\n",
      "\n",
      "\n",
      "Dataset: Scaling, Inclusion: 0, # of Abstracts 10460\n",
      "\t\tTopic 0: species, health, community, plant, effect\n",
      "\t\tTopic 1: health, care, community, service, interventions\n",
      "\t\tTopic 2: hiv, systems, network, cost, water\n",
      "\t\tTopic 3: species, spatial, pattern, land, size\n",
      "\t\tTopic 4: community, sample, species, level, water\n",
      "Dataset: Scaling, Inclusion: 1, # of Abstracts 231\n",
      "\t\tTopic 0: network, distributions, large, area, relationship\n",
      "\t\tTopic 1: economic, distributions, global, increase, pattern\n",
      "\t\tTopic 2: settlement, pattern, analysis, exponent, human\n",
      "\t\tTopic 3: network, systems, number, system, exponent\n",
      "\t\tTopic 4: spatial, network, economic, increase, systems\n",
      "\n",
      "\n",
      "Dataset: Rehab, Inclusion: 0, # of Abstracts 12819\n",
      "\t\tTopic 0: report, disorder, ptsd, symptoms, health\n",
      "\t\tTopic 1: abuse, sexual, victims, case, violence\n",
      "\t\tTopic 2: brain, injury, tbi, traumatic, group\n",
      "\t\tTopic 3: health, care, service, need, mental\n",
      "\t\tTopic 4: trauma, injury, case, injuries, hospital\n",
      "Dataset: Rehab, Inclusion: 1, # of Abstracts 220\n",
      "\t\tTopic 0: children, torture, rehabilitation, service, score\n",
      "\t\tTopic 1: care, rehabilitation, follow, pediatric, outcome\n",
      "\t\tTopic 2: limb, vascular, need, children, victims\n",
      "\t\tTopic 3: military, children, care, surgery, perform\n",
      "\t\tTopic 4: children, group, wound, injure, limb\n",
      "\n",
      "\n",
      "Dataset: WASH, Inclusion: 0, # of Abstracts 6678\n",
      "\t\tTopic 0: children, report, years, epidemic, patients\n",
      "\t\tTopic 1: control, patients, infection, isolate, outbreaks\n",
      "\t\tTopic 2: water, public, risk, children, care\n",
      "\t\tTopic 3: strain, infection, nan, infants, virus\n",
      "\t\tTopic 4: children, patients, test, infection, age\n",
      "Dataset: WASH, Inclusion: 1, # of Abstracts 249\n",
      "\t\tTopic 0: sanitation, control, hygiene, refugee, drink\n",
      "\t\tTopic 1: cholera, children, risk, refugees, outbreak\n",
      "\t\tTopic 2: hand, wash, outbreak, sanitation, control\n",
      "\t\tTopic 3: children, cholera, outbreak, report, refugee\n",
      "\t\tTopic 4: cholera, outbreak, refugees, among, community\n",
      "\n",
      "\n",
      "Dataset: ADIPP, Inclusion: 0, # of Abstracts 44402\n",
      "\t\tTopic 0: women, care, knowledge, practice, mother\n",
      "\t\tTopic 1: adolescents, risk, school, prevalence, students\n",
      "\t\tTopic 2: weight, women, pregnancy, blood, milk\n",
      "\t\tTopic 3: children, food, intake, dietary, iron\n",
      "\t\tTopic 4: patients, case, children, iodine, hiv\n",
      "Dataset: ADIPP, Inclusion: 1, # of Abstracts 4990\n",
      "\t\tTopic 0: alcohol, drink, energy, students, ci\n",
      "\t\tTopic 1: obesity, overweight, weight, body, bmi\n",
      "\t\tTopic 2: iron, women, students, breakfast, eat\n",
      "\t\tTopic 3: women, vitamin, diet, pregnant, total\n",
      "\t\tTopic 4: nutrition, obesity, eat, nutritional, rural\n",
      "\n",
      "\n",
      "Dataset: NCDS, Inclusion: 0, # of Abstracts 17883\n",
      "\t\tTopic 0: case, hospital, children, infection, clinical\n",
      "\t\tTopic 1: health, children, care, among, asthma\n",
      "\t\tTopic 2: asthma, group, cells, cell, level\n",
      "\t\tTopic 3: risk, cancer, exposure, women, effect\n",
      "\t\tTopic 4: emergency, ed, stroke, visit, care\n",
      "Dataset: NCDS, Inclusion: 1, # of Abstracts 193\n",
      "\t\tTopic 0: women, patients, cancer, children, breast\n",
      "\t\tTopic 1: cancer, treatment, patients, women, diabetes\n",
      "\t\tTopic 2: diabetes, patients, camp, children, disease\n",
      "\t\tTopic 3: diseases, diabetes, chronic, camp, patients\n",
      "\t\tTopic 4: women, diseases, diabetes, patients, prevalence\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# fit LDA for each dataset, for each label (inclusion and exclusion),\n",
    "# and print top 5 words for each topic\n",
    "for key, dataset in reviews.items():\n",
    "    for label in (0, 1):\n",
    "        print('Dataset: {}, Inclusion: {}, # of Abstracts {}'\\\n",
    "              .format(key, str(label), dataset['All_Text'][dataset.Inclusion == label].count()))\n",
    "        lda = text2lda(dataset['All_Text'][dataset.Inclusion == label], num_topics=5)\n",
    "        print_top_words(lda, 5)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes:\n",
    "   * Remove words with two letters (abbreviatinos such as ml, ui)\n",
    "   * Vitamin - Inclusion is not too informative, likely because of the small number of positive abstracts\n",
    "   * Scaling is interesting, exclusion criteria is related to \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# for key, dataset in reviews.items():\n",
    "#     print('Dataset: {}, # of Abstracts'.format(key))\n",
    "#     lda = text2lda(dataset['All_Text'], num_topics=5)\n",
    "#     print_top_words(lda, 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
